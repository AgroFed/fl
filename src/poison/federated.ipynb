{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232564c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import fl, nn, agg, data, poison, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8787d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "#log.init(\"info\", \"federated.log\")\n",
    "#log.init(\"debug\", \"flkafka.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220fa492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedArgs():\n",
    "    def __init__(self):\n",
    "        self.num_clients = 50\n",
    "        self.epochs = 10\n",
    "        self.local_rounds = 1\n",
    "        self.client_batch_size = 32\n",
    "        self.test_batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.cuda = False\n",
    "        self.seed = 1\n",
    "        self.tb = SummaryWriter('../../out/runs/federated/FLTrust', comment=\"Mnist Centralized Federated training\")\n",
    "\n",
    "fedargs = FedArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c959a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a548fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e7ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Global and Client models\n",
    "global_model = nn.ModelMNIST()\n",
    "client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "# Function for training\n",
    "def train_model(_model, train_loader, fedargs, device):\n",
    "    model, loss = fl.client_update(_model,\n",
    "                                train_loader,\n",
    "                                fedargs.learning_rate,\n",
    "                                fedargs.weight_decay,\n",
    "                                fedargs.local_rounds,\n",
    "                                device)\n",
    "    model_update = agg.sub_model(_model, model)\n",
    "    return model_update, model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983f5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Data to clients\n",
    "train_data, test_data = data.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510951bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For securing if the next cell execution is skipped\n",
    "FLTrust = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c2041",
   "metadata": {},
   "source": [
    "<h1>FLTrust: Skip section below for any other averaging than FLTrust.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2b8b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLTrust = True\n",
    "root_ratio = 0.01\n",
    "train_data, root_data = torch.utils.data.random_split(train_data, [int(len(train_data) * (1-root_ratio)), \n",
    "                                                              int(len(train_data) * root_ratio)])\n",
    "root_loader = torch.utils.data.DataLoader(root_data, batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1378ffa",
   "metadata": {},
   "source": [
    "<h2>Resume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6251a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cef4fa",
   "metadata": {},
   "source": [
    "<h1>Poison: Skip section below to run normal, modify if required.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54367b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for client in range(10):\n",
    "    clients_data[clients[client]] = poison.label_flip(clients_data[clients[client]], 4, 9, poison_percent = -1)\n",
    "    \n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 6, 2, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 3, 8, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 1, 5, poison_percent = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80861b32",
   "metadata": {},
   "source": [
    "<h2>Resume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ccdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "clients_info = {\n",
    "        client: {\"train_loader\": client_train_loaders[client]}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9e82171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = train_model(model, train_loader, fedargs, device)\n",
    "\n",
    "    #Plot and Log\n",
    "    for local_epoch, loss in enumerate(list(loss.values())):\n",
    "        fedargs.tb.add_scalars(\"Training Loss/\" + client, {str(epoch): loss}, str(local_epoch + 1))\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274d1e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2021-08-25 13:30:32,743 - <ipython-input-12-37a1a8ad3668>::<module>(l:8) : Federated Training Epoch 1 of 25 [MainProcess : MainThread (INFO)]\n",
      "  4%|▍         | 1/25 [00:39<15:59, 39.98s/it]2021-08-25 13:31:12,486 - <ipython-input-12-37a1a8ad3668>::<module>(l:8) : Federated Training Epoch 2 of 25 [MainProcess : MainThread (INFO)]\n",
      "  4%|▍         | 1/25 [00:46<18:25, 46.08s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'attack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-37a1a8ad3668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         fedargs.tb.add_scalars(\"Test Evaluation\", {\n\u001b[1;32m     27\u001b[0m             \u001b[0;34m'Gloabl Accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglobal_test_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;34m'Attack Success Rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglobal_test_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attack\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attack_success_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;34m'Misclassification Rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglobal_test_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attack\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"misclassification_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         }, epoch)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attack'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for _epoch in tqdm(range(fedargs.epochs)):\n",
    "\n",
    "    epoch = _epoch + 1\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Gloabal Model Update\n",
    "    if epoch > 1:\n",
    "        # For Tmean, not impacts others as of now\n",
    "        avgargs = {\"beta\": 10}\n",
    "        \n",
    "        # For FLTrust, if FLTrust section is skipped, this piece of code will be ignored automatically\n",
    "        if FLTrust:\n",
    "            global_model_update, _, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "            avgargs[\"base_update\"] = global_model_update\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_model_updates, global_model, agg.Rule.FLTrust, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {} of {} : Server Update\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Test\n",
    "        global_test_output = fl.eval(global_model, test_loader, device, 4, 9)\n",
    "        fedargs.tb.add_scalars(\"Test Evaluation\", {\n",
    "            'Gloabl Accuracy': global_test_output[\"accuracy\"],\n",
    "            'Attack Success Rate': global_test_output[\"attack\"][\"attack_success_rate\"],\n",
    "            'Misclassification Rate': global_test_output[\"attack\"][\"misclassification_rate\"],\n",
    "        }, epoch)\n",
    "        log.jsoninfo(global_test_output, \"Gloabl Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "    \n",
    "        # Update client models\n",
    "        client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "    # Clients\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [process(client, epoch, client_models[client],\n",
    "                     clients_info[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    updates = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    client_model_updates = {client: update for client, update in zip(clients, updates)}\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01090c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
