{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from mxnet import nd as mnd\n",
    "import heapq\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import fl, nn, agg, data, poison, log, sim, resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"debug\")\n",
    "#log.init(\"info\", \"federated.log\")\n",
    "#log.init(\"debug\", \"flkafka.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedArgs():\n",
    "    def __init__(self):\n",
    "        self.num_clients = 50\n",
    "        self.epochs = 10\n",
    "        self.local_rounds = 1\n",
    "        self.client_batch_size = 32\n",
    "        self.test_batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.cuda = True\n",
    "        self.seed = 1\n",
    "        self.tb = SummaryWriter('../../out/runs/federated/FLTrust', comment=\"Mnist Centralized Federated training\")\n",
    "\n",
    "fedargs = FedArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Global and Client models\n",
    "#global_model = nn.ModelMNIST()\n",
    "global_model = resnet.ResNet18()\n",
    "client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "# Function for training\n",
    "def train_model(_model, train_loader, fedargs, device):\n",
    "    model, loss = fl.client_update(_model,\n",
    "                                train_loader,\n",
    "                                fedargs.learning_rate,\n",
    "                                fedargs.weight_decay,\n",
    "                                fedargs.local_rounds,\n",
    "                                device)\n",
    "    model_update = agg.sub_model(_model, model)\n",
    "    return model_update, model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST Data to clients\n",
    "train_data, test_data = data.load_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49900 100\n"
     ]
    }
   ],
   "source": [
    "# For FLTrust\n",
    "#############Skip this section for running other averaging\n",
    "FLTrust = True\n",
    "root_ratio = 0.002\n",
    "train_data, root_data = torch.utils.data.random_split(train_data, [int(len(train_data) * (1-root_ratio)), \n",
    "                                                              int(len(train_data) * root_ratio)])\n",
    "root_loader = torch.utils.data.DataLoader(root_data, batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "print(len(train_data), len(root_data))\n",
    "\n",
    "#global_model, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "#client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison a client\n",
    "################Skip this section for running without poison\n",
    "#for client in range(2):\n",
    "#    clients_data[clients[client]] = poison.label_flip(clients_data[clients[client]], 4, 9, poison_percent = -1)\n",
    "    \n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 6, 2, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 3, 8, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 1, 5, poison_percent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "clients_info = {\n",
    "        client: {\"train_loader\": client_train_loaders[client]}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = resnet.ResNet18()\n",
    "B1 = copy.deepcopy(global_model)\n",
    "C1 = copy.deepcopy(global_model)\n",
    "C2 = copy.deepcopy(global_model)\n",
    "\n",
    "C3 = copy.deepcopy(global_model)\n",
    "C4 = copy.deepcopy(global_model)\n",
    "C5 = copy.deepcopy(global_model)\n",
    "\n",
    "def copy_model(B1, C1, C2, C3, C4, C5, _model):\n",
    "    B1 = copy.deepcopy(_model)\n",
    "    C1 = copy.deepcopy(_model)\n",
    "    C2 = copy.deepcopy(_model)\n",
    "\n",
    "    C3 = copy.deepcopy(_model)\n",
    "    C4 = copy.deepcopy(_model)\n",
    "    C5 = copy.deepcopy(_model)\n",
    "    \n",
    "    return B1, C1, C2, C3, C4, C5\n",
    "\n",
    "B1, C1, C2, C3, C4, C5 = copy_model(B1, C1, C2, C3, C4, C5, global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Pass\n",
      "{'test_loss': -0.04180281018018722, 'correct': 1000, 'accuracy': 10.0}\n",
      "Here1 -0.3496783\n",
      "Here2 -0.34766108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh_1921cs01/hub/F3IA/fl/libs/sim.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  _param_list = nd.array(param_list).squeeze()\n",
      "2021-09-03 22:36:11,615 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:96) : FLTrust Score [0.132, 0.129, 0.133, 0.116, 0.121] [MainProcess : MainThread (INFO)]\n",
      "2021-09-03 22:36:11,628 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:97) : FLTrust Score [0.00030560826, 0.00031466072, 0.036736965, 0.03260129, 0.034027442] [MainProcess : MainThread (INFO)]\n"
     ]
    }
   ],
   "source": [
    "t1 = global_model\n",
    "\n",
    "for i in range(5):\n",
    "    _B1, B1, _ = train_model(B1, root_loader, fedargs, device)\n",
    "    \n",
    "    print(fl.eval(B1, test_loader, device))\n",
    "\n",
    "    _C1, C1, _ = train_model(C1, clients_info[list(clients_info.keys())[0]]['train_loader'], fedargs, device)\n",
    "    _C2, C2, _ = train_model(C2, clients_info[list(clients_info.keys())[1]]['train_loader'], fedargs, device)\n",
    "\n",
    "    _C3, C3, _ = train_model(C3, clients_info[list(clients_info.keys())[2]]['train_loader'], fedargs, device)\n",
    "    _C4, C4, _ = train_model(C4, clients_info[list(clients_info.keys())[3]]['train_loader'], fedargs, device)\n",
    "    _C5, C5, _ = train_model(C5, clients_info[list(clients_info.keys())[4]]['train_loader'], fedargs, device)\n",
    "    \n",
    "    fb1, bslist = sim.get_net_arr(_B1)\n",
    "    fc1, cslist = sim.get_net_arr(_C1)\n",
    "    fc2, cslist = sim.get_net_arr(_C2)\n",
    "    fc4, cslist = sim.get_net_arr(_C4)\n",
    "    fc5, cslist = sim.get_net_arr(_C5)\n",
    "\n",
    "    g = fc1\n",
    "    np5 = (g - fb1)\n",
    "    fc11 = copy.deepcopy(g)\n",
    "    \n",
    "    dot_mb = sim.dot(fb1, fc11)\n",
    "    norm_m = sim.norm(fc11)\n",
    "    norm_g = sim.norm(g)\n",
    "    ts_mb = (dot_mb * norm_g)\n",
    "    sim_mg = sim.cosine_similarity(g, fc11)\n",
    "    \n",
    "    for index in heapq.nlargest(int(len(np5)), range(len(np5)), np5.take):\n",
    "        #[index] = fc11[index] + (2* np5[index])\n",
    "        fc11, dot_mb, norm_m, sim_mg = sim.cosine_coord_vector_adapter(fb1, fc11, index, dot_mb, norm_m, sim_mg, g, norm_g)\n",
    "\n",
    "    cos1 = sim.cosine_similarity(g, fc11)\n",
    "    print(\"Here1\", cos1)\n",
    "    #np.random.shuffle(np5)\n",
    "\n",
    "    #V1                       V2\n",
    "    #1, 2, 3, 4.              2, 4, 6, 8\n",
    "    #CS = 1\n",
    "\n",
    "    #np5 = 1, 2, 3, 4\n",
    "    #np5.shuffle = 3, 4, 1, 2\n",
    "\n",
    "    #V3 = 4, 6, 4, 6\n",
    "    #CS = .87\n",
    "\n",
    "    #fc11 = fb1 + np5\n",
    "    #cs11 = mnd.dot(mnd.array(fb1), mnd.array(fc11)) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(fc11)) + 1e-9)\n",
    "    #print(cs11)\n",
    "\n",
    "    #fc11 = 2 * fb1\n",
    "    fc11 = sim.get_arr_net(_C1, fc11, cslist)\n",
    "    #print(sim.grad_cosine_similarity(_B1, fc11))\n",
    "\n",
    "    #np.random.shuffle(np5)\n",
    "\n",
    "    #fc22 = fb1 + np5\n",
    "    #cs22 = mnd.dot(mnd.array(fb1), mnd.array(fc22)) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(fc22)) + 1e-9)\n",
    "    #print(cs22)\n",
    "\n",
    "    g = fc2\n",
    "    np5 = (g - fb1)\n",
    "    fc22 = copy.deepcopy(g)\n",
    "    \n",
    "    dot_mb = sim.dot(fb1, fc22)\n",
    "    norm_m = sim.norm(fc22)\n",
    "    norm_g = sim.norm(g)\n",
    "    sim_mg = sim.cosine_similarity(g, fc22)\n",
    "    \n",
    "    for index in heapq.nsmallest(int(len(np5)), range(len(np5)), np5.take):\n",
    "        #fc22[index] = fc22[index] + (2* np5[index])\n",
    "        fc22, dot_mb, norm_m, sim_mg = sim.cosine_coord_vector_adapter(fb1, fc22, index, dot_mb, norm_m, sim_mg, g, norm_g)\n",
    "\n",
    "    cos2 = sim.cosine_similarity(g, fc22)\n",
    "    print(\"Here2\", cos2)\n",
    "    \n",
    "#    _m = fc11\n",
    "#    if cos2 < cos1:\n",
    "#        _m = fc22\n",
    "\n",
    "    #fc22 = 2 * fb1\n",
    "    fc22 = sim.get_arr_net(_C2, fc22, cslist)\n",
    "    #print(sim.grad_cosine_similarity(_B1, fc22))\n",
    "\n",
    "    avgargs = {\"base_update\": _B1, \"base_norm\": True}\n",
    "    global_model = fl.federated_avg({'a': fc11, 'b': fc22, 'c': _C3, 'd': _C4, 'e': _C5}, B1, agg.Rule.FLTrust, **avgargs)\n",
    "    \n",
    "    B1, C1, C2, C3, C4, C5 = copy_model(B1, C1, C2, C3, C4, C5, global_model)\n",
    "    \n",
    "    print(fl.eval(global_model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 2.2434592235565187, 'correct': 2973, 'accuracy': 29.73}\n",
      "{'test_loss': 2.193963765716553, 'correct': 2421, 'accuracy': 24.21}\n",
      "{'test_loss': 2.1275648666381834, 'correct': 3397, 'accuracy': 33.97}\n",
      "{'test_loss': 2.0540388984680176, 'correct': 3535, 'accuracy': 35.35}\n",
      "{'test_loss': 1.9639019832611084, 'correct': 4636, 'accuracy': 46.36}\n",
      "{'test_loss': 1.889145348739624, 'correct': 5460, 'accuracy': 54.6}\n",
      "{'test_loss': 1.780853052520752, 'correct': 5454, 'accuracy': 54.54}\n",
      "{'test_loss': 1.6839838970184327, 'correct': 5901, 'accuracy': 59.01}\n",
      "{'test_loss': 1.595321806526184, 'correct': 5839, 'accuracy': 58.39}\n",
      "{'test_loss': 1.509443727874756, 'correct': 6247, 'accuracy': 62.470000000000006}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _B1, B1, _ = train_model(B1, root_loader, fedargs, device)\n",
    "    print(fl.eval(B1, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fc1))\n",
    "print(np.count_nonzero(fc1))\n",
    "print(len(np.intersect1d(fb1, fc1)))\n",
    "print(len(np.where(fc1>fb1-0.0001)[0]))\n",
    "print(len(np.where(fc1==fb1)[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df1 = fc1 - fb1\n",
    "unique, counts = np.unique(df1, return_counts=True)\n",
    "npc = np.asarray((unique, counts)).T\n",
    "print(np.amax(df1))\n",
    "\n",
    "plt.plot(npc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199882\n",
      "1199882\n",
      "104000\n",
      "650268\n",
      "1\n",
      "0.0048349625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(fc5))\n",
    "print(np.count_nonzero(fc5))\n",
    "print(len(np.intersect1d(fb1, fc5)))\n",
    "print(len(np.where(fc5>fb1-0.0001)[0]))\n",
    "print(len(np.where(fc5==fb1)[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df5 = fc5 - fb1\n",
    "unique, counts = np.unique(df5, return_counts=True)\n",
    "npc = np.asarray((unique, counts)).T\n",
    "print(np.amax(df5))\n",
    "\n",
    "plt.plot(npc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def sub_model(model1, model2):\n",
    "    params1 = model1.state_dict().copy()\n",
    "    params2 = model2.state_dict().copy()\n",
    "    \n",
    "    params1['conv1.weight'] = params2['conv1.weight']\n",
    "    #params1['fc1.weight'] = params2['fc1.weight']\n",
    "    \n",
    "    model = copy.deepcopy(model1)\n",
    "    model.load_state_dict(params1, strict=False)\n",
    "    return model\n",
    "\n",
    "_C1_ = copy.deepcopy(_C1)\n",
    "_C1_ = sub_model(_B1, _C1_)\n",
    "\n",
    "_C2_ = copy.deepcopy(_C2)\n",
    "_C2_ = sub_model(_B1, _C2_)\n",
    "\n",
    "#print(sim.grad_cosine_similarity(_B1, _C1_))\n",
    "#print(sim._grad_cosine_similarity(_B1, _C1_))\n",
    "\n",
    "avgargs = {\"base_update\": _B1}\n",
    "t1 = fl.federated_avg({'a': _C1, 'b': _C2, 'c': _C3, 'd': _C4, 'e': _C5}, B1, agg.Rule.FLTrust, **avgargs)\n",
    "t2 = fl.federated_avg({'a': _C1_, 'b': _C2_, 'c': _C3, 'd': _C4, 'e': _C5}, B1, agg.Rule.FLTrust, **avgargs)\n",
    "\n",
    "print(fl.eval(t1, test_loader, device))\n",
    "print(fl.eval(t2, test_loader, device))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel=nn.denoising_model().to(device)\\ncriterion=torch.nn.MSELoss()\\noptimizer=optim.SGD(model.parameters(),lr=0.5,weight_decay=1e-5)\\n\\noutput = fc1\\nmodel.train()\\nfor epcoh in range(10):\\n    optimizer.zero_grad()\\n    output = model(torch.from_numpy(fc1))\\n    cs1 = mnd.dot(mnd.array(fb1), mnd.array(output.detach().numpy())) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(output.detach().numpy())) + 1e-9)\\n    _loss = criterion(output, torch.from_numpy(fb1))\\n    _loss = _loss + (1 - cs1.asnumpy()[0])\\n    print(_loss)\\n    _loss.backward()\\n    optimizer.step()\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model=nn.denoising_model().to(device)\n",
    "criterion=torch.nn.MSELoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.5,weight_decay=1e-5)\n",
    "\n",
    "output = fc1\n",
    "model.train()\n",
    "for epcoh in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(torch.from_numpy(fc1))\n",
    "    cs1 = mnd.dot(mnd.array(fb1), mnd.array(output.detach().numpy())) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(output.detach().numpy())) + 1e-9)\n",
    "    _loss = criterion(output, torch.from_numpy(fb1))\n",
    "    _loss = _loss + (1 - cs1.asnumpy()[0])\n",
    "    print(_loss)\n",
    "    _loss.backward()\n",
    "    optimizer.step()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1, 1, 1]\n",
    "g = [1, 2, 3]\n",
    "#b-g = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9258202\n",
      "0.92582 0.8367346\n",
      "[1, 2, 0.8181812470752238]\n",
      "0.9258199 0.8205977\n",
      "[1, 0.3140487202791258, 0.8181812470752238]\n",
      "0.9258199 0.8205977\n",
      "[1, 0.3140487202791258, 0.8181812470752238]\n",
      "0.018163681030273438\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "m = copy.deepcopy(g)\n",
    "dot_bm = sim.dot(b, m)\n",
    "norm_m = sim.norm(m)\n",
    "norm_g = sim.norm(g)\n",
    "sim_mg = sim.cosine_similarity(m, g)\n",
    "\n",
    "print(sim_bg)\n",
    "\n",
    "for coord in reversed(range(len(b))):\n",
    "    m, dot_bm, norm_m, sim_mg = sim.cosine_coord_vector_adapter(b, m, coord, dot_bm, norm_m, sim_mg, g, norm_g)\n",
    "    \n",
    "    print(sim.cosine_similarity(b, m), sim.cosine_similarity(g, m))\n",
    "    print(m)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhessian import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for inputs, targets in root_loader:\n",
    "    break\n",
    "hessian_comp = hessian(_B1, criterion, data=(inputs, targets), cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-434-d09ae4b8d551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_eigenvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#tev, tevlist = sim.get_net_arr(top_eigenvector[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "tev = top_eigenvector[0]\n",
    "tev = tev.unsqueeze(0)\n",
    "print(tev.shape)\n",
    "#tev, tevlist = sim.get_net_arr(top_eigenvector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
