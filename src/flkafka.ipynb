{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a77f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#!pip install networkx matplotlib\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from libs.topology_manager import *\n",
    "from libs import fl, nn, data, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9749cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "#log.init(\"info\")\n",
    "#log.init(\"info\", \"federated.log\")\n",
    "log.init(\"debug\", \"flkafka.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f22545",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = np.array([[0,1,1,1,1,1],\n",
    "             [1,0,0,0,0,0],\n",
    "             [1,0,0,0,0,0],\n",
    "             [1,0,0,0,0,0],\n",
    "             [1,0,0,0,0,0], \n",
    "             [1,0,0,0,0,0]])\n",
    "\n",
    "node_type = {'aggregator': [0,1], 'trainer': [2,3], 'broadcaster': [4,5]}\n",
    "\n",
    "di_graph = nx.DiGraph(adj_mat)\n",
    "#nx.draw(di_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0623fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedArgs():\n",
    "    def __init__(self):\n",
    "        self.num_clients = len(adj_mat)\n",
    "        self.epochs = 10\n",
    "        self.local_rounds = 1\n",
    "        self.client_batch_size = 32\n",
    "        self.test_batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.cuda = False\n",
    "        self.seed = 1\n",
    "        self.topic = 'pyflx'\n",
    "        self.tb = SummaryWriter('../out/runs/flkafka', comment=\"Mnist Distributed Federated training\")\n",
    "\n",
    "fedargs = FedArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3022ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8de969",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]\n",
    "ctp = CentralizedTopology(adj_mat, clients, node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7283a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Data to clients\n",
    "train_data, test_data = data.load_mnist_dataset()\n",
    "clients_data = data.split_data(train_data, clients)\n",
    "client_loaders, test_loader = data.load_client_data(clients_data, fedargs.client_batch_size, test_data, fedargs.test_batch_size, **kwargs)\n",
    "\n",
    "# Load preliminary models\n",
    "# if want to do random initialization, replace copy.deepcopy(global_model) with nn.ModelMNIST() and vice versa\n",
    "global_model = nn.ModelMNIST().to(device)\n",
    "clients_info = {\n",
    "        client: {\"model\": nn.ModelMNIST().to(device), \"loss\": {}, \"data_loader\": client_loaders[client]}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280fc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch):\n",
    "    log.info(\"Processing Client {}\".format(client))\n",
    "\n",
    "    #Train    \n",
    "    clients_info[client]['model'], clients_info[client]['loss'] = fl.client_update(clients_info[client]['model'],\n",
    "                                                                                clients_info[client]['data_loader'],\n",
    "                                                                                fedargs.learning_rate,\n",
    "                                                                                fedargs.weight_decay,\n",
    "                                                                                fedargs.local_rounds,\n",
    "                                                                                device)\n",
    "    \n",
    "    ctp.produce_model(client, fedargs.topic, clients_info[client]['model'], epoch)\n",
    "\n",
    "    '''\n",
    "    for local_epoch, loss in enumerate(list(clients_info[client]['loss'].values())):\n",
    "        fedargs.tb.add_scalars(\"Training Loss/\" + client,\n",
    "                               {str(epoch): loss},\n",
    "                               str(local_epoch + 1))\n",
    "    '''\n",
    "\n",
    "    log.jsondebug(clients_info[client]['loss'],\n",
    "                 \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, \n",
    "                                                                      fedargs.epochs, \n",
    "                                                                      client))\n",
    "    log.modeldebug(clients_info[client]['model'],\n",
    "                   \"Epoch {} of {} : Client {} Update\".format(epoch, \n",
    "                                                              fedargs.epochs, \n",
    "                                                              client))\n",
    "\n",
    "    #Test\n",
    "    test_output = fl.eval(clients_info[client]['model'], test_loader, device)\n",
    "    \n",
    "    fedargs.tb.add_scalar(\"Accuracy/\" + client, test_output[\"accuracy\"], epoch)\n",
    "    \n",
    "    log.jsoninfo(test_output, \n",
    "                 \"Test Outut after Epoch {} of {} for Client {}\".format(epoch, fedargs.epochs, client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc40c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:51<00:00, 53.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531.5373432636261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Federated Training\n",
    "for _epoch in tqdm(range(fedargs.epochs)):\n",
    "\n",
    "    epoch = _epoch + 1\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "    \n",
    "    for client in clients:\n",
    "        # Average, epoch passed is actually prev epoch, for which we want to consume updates\n",
    "        rcvd_models = ctp.consume_model(client, fedargs.topic, nn.ModelMNIST(), _epoch)\n",
    "        log.info(\"Client {} received {} model updates\".format(client, len(rcvd_models)))\n",
    "        if len(rcvd_models) != 0:\n",
    "            clients_info[client]['model'] = fl.federated_avg(rcvd_models)\n",
    "\n",
    "    tasks = [process(client, epoch) for client in clients]\n",
    "    await asyncio.wait(tasks)\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42843549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
