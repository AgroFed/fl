{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232564c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio, copy, os, pickle, socket, sys, time\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Process\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from libs import agg, data, fl, log, nn, poison, resnet, sim, text_utils\n",
    "from cfgs.fedargs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8787d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "#log.init(\"info\", \"poison.log\")\n",
    "#log.init(\"debug\", \"poison.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512a472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkasyah\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kasyah/fl/runs/r4dfj290\" target=\"_blank\">iconic-blaze-1</a></strong> to <a href=\"https://wandb.ai/kasyah/fl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Start a new run, tracking hyperparameters in config\n",
    "wandb.init(project=\"fl\", config={\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"MNIST\",\n",
    "})\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220fa492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make changes as required by looking at cfgs/fedargs\n",
    "fedargs.tb = SummaryWriter('../out/runs/federated/run', comment=\"fl\")\n",
    "fedargs.agg_rule = agg.Rule.FedAvg\n",
    "#fedargs.dataset = \"agnews\" # \"cifar\" for cifar-10,\"fmnist\" for fmnist, \"agnews\" for agnews, wisconsin for Wisconsin\n",
    "#fedargs.model = nn.CharCNN(70) #resnet.ResNet18() for cifar10, nn.CharCNN(70) for agnews, nn.WisconsinModel for Wisconsin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c959a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device settings\n",
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a548fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clients\n",
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e7ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Global and Client models\n",
    "global_model = copy.deepcopy(fedargs.model)\n",
    "# Load Data to clients\n",
    "train_data, test_data = data.load_dataset(fedargs.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c2041",
   "metadata": {},
   "source": [
    "<h2>FLTrust</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b8b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLTrust[\"is\"]:\n",
    "    train_data, FLTrust[\"data\"] = data.random_split(train_data, FLTrust[\"ratio\"])\n",
    "    FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    if FLTrust[\"proxy\"][\"is\"]:\n",
    "        FLTrust[\"data\"], FLTrust[\"proxy\"][\"data\"] = data.random_split(FLTrust[\"data\"], FLTrust[\"proxy\"][\"ratio\"])\n",
    "        FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "        FLTrust[\"proxy\"][\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"proxy\"][\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f39ac",
   "metadata": {},
   "source": [
    "<h2>Prepare a backdoored loader for test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4118be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    train_data, backdoor_attack[\"data\"] = data.random_split(train_data, backdoor_attack[\"ratio\"])\n",
    "    backdoor_attack[\"data\"] = poison.insert_trojan(backdoor_attack[\"data\"],\n",
    "                                                   backdoor_attack[\"target_label\"],\n",
    "                                                   backdoor_attack[\"trojan_func\"], 1)\n",
    "    backdoor_attack[\"loader\"] = torch.utils.data.DataLoader(backdoor_attack[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3b884",
   "metadata": {},
   "source": [
    "<h2>Load client's data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6251a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ce3b5",
   "metadata": {},
   "source": [
    "<h2>Label Flip Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54367b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_flip_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = label_flip_attack[\"func\"](clients_data[clients[client]],\n",
    "                                                                  label_flip_attack[\"labels\"],\n",
    "                                                                  label_flip_attack[\"percent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701bd1b",
   "metadata": {},
   "source": [
    "<h2>Backdoor Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154887e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = poison.insert_trojan(clients_data[clients[client]],\n",
    "                                                             backdoor_attack[\"target_label\"],\n",
    "                                                             backdoor_attack[\"trojan_func\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ccdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "client_details = {\n",
    "        client: {\"train_loader\": client_train_loaders[client],\n",
    "                 \"model\":  copy.deepcopy(global_model),\n",
    "                 \"model_update\": None}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e82171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = fedargs.train_func(model, train_loader, \n",
    "                                                   fedargs.learning_rate,\n",
    "                                                   fedargs.weight_decay,\n",
    "                                                   fedargs.local_rounds, device)\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d1e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]2021-10-18 00:35:58,248 - <ipython-input-15-9bd942c8db4d>::<module>(l:8) : Federated Training Epoch 1 of 50 [MainProcess : MainThread (INFO)]\n",
      "  2%|‚ñè         | 1/50 [02:22<1:56:19, 142.45s/it]2021-10-18 00:38:20,342 - <ipython-input-15-9bd942c8db4d>::<module>(l:8) : Federated Training Epoch 2 of 50 [MainProcess : MainThread (INFO)]\n",
      "2021-10-18 00:38:28,972 - <ipython-input-15-9bd942c8db4d>::<module>(l:26) : Global Test Outut after Epoch 2 of 50 {\n",
      "    \"accuracy\": 79.78,\n",
      "    \"correct\": 7978,\n",
      "    \"test_loss\": 0.9545446258068084\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  4%|‚ñç         | 2/50 [04:32<1:48:19, 135.41s/it]2021-10-18 00:40:30,833 - <ipython-input-15-9bd942c8db4d>::<module>(l:8) : Federated Training Epoch 3 of 50 [MainProcess : MainThread (INFO)]\n",
      "2021-10-18 00:40:39,517 - <ipython-input-15-9bd942c8db4d>::<module>(l:26) : Global Test Outut after Epoch 3 of 50 {\n",
      "    \"accuracy\": 89.34,\n",
      "    \"correct\": 8934,\n",
      "    \"test_loss\": 0.4225286979198456\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  6%|‚ñå         | 3/50 [06:06<1:31:03, 116.25s/it]2021-10-18 00:42:04,264 - <ipython-input-15-9bd942c8db4d>::<module>(l:8) : Federated Training Epoch 4 of 50 [MainProcess : MainThread (INFO)]\n",
      "2021-10-18 00:42:12,741 - <ipython-input-15-9bd942c8db4d>::<module>(l:26) : Global Test Outut after Epoch 4 of 50 {\n",
      "    \"accuracy\": 91.5,\n",
      "    \"correct\": 9150,\n",
      "    \"test_loss\": 0.3239502674937248\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  8%|‚ñä         | 4/50 [07:55<1:26:50, 113.26s/it]2021-10-18 00:43:52,955 - <ipython-input-15-9bd942c8db4d>::<module>(l:8) : Federated Training Epoch 5 of 50 [MainProcess : MainThread (INFO)]\n",
      "2021-10-18 00:44:00,867 - <ipython-input-15-9bd942c8db4d>::<module>(l:26) : Global Test Outut after Epoch 5 of 50 {\n",
      "    \"accuracy\": 92.58,\n",
      "    \"correct\": 9258,\n",
      "    \"test_loss\": 0.2766506089821458\n",
      "} [MainProcess : MainThread (INFO)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for _epoch in tqdm(range(fedargs.epochs)):\n",
    "\n",
    "    epoch = _epoch + 1\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Gloabal Model Update\n",
    "    if epoch > 1:\n",
    "        # For Tmean and FLTrust, not impacts others as of now\n",
    "        avgargs = {\"beta\": len(mal_clients), \n",
    "                   \"base_model_update\": global_model_update if FLTrust[\"is\"] else None,\n",
    "                   \"base_norm\": True}\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_model_updates, global_model, fedargs.agg_rule, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {} of {} : Server Update\".format(epoch, fedargs.epochs))\n",
    "        \n",
    "        # Test\n",
    "        global_test_output = fedargs.eval_func(global_model, test_loader, device, label_flip_attack[\"labels\"])\n",
    "        fedargs.tb.add_scalar(\"Gloabl Accuracy/\", global_test_output[\"accuracy\"], epoch)\n",
    "        fedargs.tb.add_scalar(\"Gloabl Test Loss/\", global_test_output[\"test_loss\"], epoch)\n",
    "        wandb.log({\"epoch\":epoch, \"acc\":global_test_output[\"accuracy\"], \"loss\": global_test_output[\"test_loss\"]})\n",
    "        log.jsoninfo(global_test_output, \"Global Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "        \n",
    "        # Evaluate LFA\n",
    "        if \"attack\" in global_test_output:\n",
    "            if \"attack_success_rate\" in global_test_output[\"attack\"]:\n",
    "                fedargs.tb.add_scalar(\"Attack Success Rate/\", global_test_output[\"attack\"][\"attack_success_rate\"], epoch)\n",
    "                wandb.log({\"attack_success_rate\": global_test_output[\"attack\"][\"attack_success_rate\"]})\n",
    "            if \"misclassification_rate\" in global_test_output[\"attack\"]:\n",
    "                fedargs.tb.add_scalar(\"Misclassification Rate/\", global_test_output[\"attack\"][\"misclassification_rate\"], epoch)\n",
    "                wandb.log({\"misclassification_rate\": global_test_output[\"attack\"][\"misclassification_rate\"]})\n",
    "\n",
    "        # Evaluate Backdoor\n",
    "        if backdoor_attack[\"is\"]:\n",
    "            backdoor_test_output = fl.backdoor_test(global_model, backdoor_attack[\"loader\"], device,\n",
    "                                                                backdoor_attack[\"target_label\"])\n",
    "            fedargs.tb.add_scalar(\"Backdoor Success Rate/\", backdoor_test_output[\"accuracy\"], epoch)\n",
    "            wandb.log({\"backdoor_success_rate\": backdoor_test_output[\"accuracy\"]})\n",
    "            log.jsoninfo(backdoor_test_output, \"Backdoor Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Update client models\n",
    "        for client in clients:\n",
    "            client_details[client]['model'] = copy.deepcopy(global_model)\n",
    "\n",
    "    # Clients\n",
    "    tasks = [process(client, epoch, client_details[client]['model'],\n",
    "                     client_details[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    try:\n",
    "        updates = fedargs.loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        print(\"Caught keyboard interrupt. Canceling tasks...\")\n",
    "        tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        tasks.exception()\n",
    "\n",
    "    for client, update in zip(clients, updates):\n",
    "        client_details[client]['model_update'] = update\n",
    "    client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "    \n",
    "    # Fang attack\n",
    "    if fang_attack[\"is\"]:\n",
    "        client_model_updates = fang_attack[\"func\"](client_model_updates, len(mal_clients), fang_attack[\"kn\"])\n",
    "        \n",
    "    # LIE attack\n",
    "    if lie_attack[\"is\"]:\n",
    "        client_model_updates = lie_attack[\"func\"](client_model_updates, len(mal_clients), lie_attack[\"kn\"])\n",
    "        \n",
    "    # SOTA attack\n",
    "    if sota_attack[\"is\"]:\n",
    "        client_model_updates = sota_attack[\"func\"](client_model_updates, len(mal_clients), \n",
    "                                                   sota_attack[\"kn\"], sota_attack[\"dev_type\"])    \n",
    "    \n",
    "    if FLTrust[\"is\"]:\n",
    "        global_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"loader\"],\n",
    "                                                       fedargs.learning_rate,\n",
    "                                                       fedargs.weight_decay,\n",
    "                                                       fedargs.local_rounds, device)\n",
    "\n",
    "        # For Attacks related to FLTrust\n",
    "        base_model_update = global_model_update\n",
    "        if FLTrust[\"proxy\"][\"is\"]:\n",
    "            base_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"proxy\"][\"loader\"],\n",
    "                                                         fedargs.learning_rate,\n",
    "                                                         fedargs.weight_decay,\n",
    "                                                         fedargs.local_rounds, device)\n",
    "            \n",
    "        if layer_replacement_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = layer_replacement_attack[\"func\"](base_model_update,\n",
    "                                                                                                   client_details[clients[client]]['model_update'],\n",
    "                                                                                                   layer_replacement_attack[\"layers\"])\n",
    "\n",
    "        # For cosine attack, Malicious Clients\n",
    "        if cosine_attack[\"is\"]:\n",
    "            p_models, params_changed = cosine_attack[\"func\"](base_model_update, cosine_attack[\"args\"], epoch,\n",
    "                                                             client_model_updates, len(mal_clients), cosine_attack[\"kn\"])\n",
    "            \n",
    "            for client, p_model in enumerate(p_models):\n",
    "                client_details[clients[client]]['model_update'] = p_model \n",
    "\n",
    "            #plot params changed for only one client\n",
    "            fedargs.tb.add_scalar(\"Params Changed for Cosine Attack/\", params_changed, epoch)\n",
    "\n",
    "        # For sybil attack, Malicious Clients\n",
    "        if sybil_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = base_model_update\n",
    "                \n",
    "        # again pair, as changed during attack\n",
    "        client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7cf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac74b2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1> End </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
