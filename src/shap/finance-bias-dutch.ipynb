{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d6b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkasyap/anaconda3/envs/menv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import data as dt, neuronshap as ns, sim\n",
    "from cfgs.fedargs import *\n",
    "\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    demographic_parity_ratio,\n",
    "    equalized_odds_difference,\n",
    "    equalized_odds_ratio,\n",
    ")\n",
    "from libs.helpers.finance import bin_hours_per_week, bin_edu_level, bin_age_level, bin_marital_status_level\n",
    "from libs.helpers.metrics import (\n",
    "    conditional_demographic_parity_difference,\n",
    "    conditional_demographic_parity_ratio,\n",
    ")\n",
    "from libs.helpers.plot import group_box_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03742d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/dutch/dutch.csv')\n",
    "#df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d8031e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60420 entries, 0 to 60419\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   sex                   60420 non-null  int64\n",
      " 1   age                   60420 non-null  int64\n",
      " 2   household_position    60420 non-null  int64\n",
      " 3   household_size        60420 non-null  int64\n",
      " 4   prev_residence_place  60420 non-null  int64\n",
      " 5   citizenship           60420 non-null  int64\n",
      " 6   country_birth         60420 non-null  int64\n",
      " 7   edu_level             60420 non-null  int64\n",
      " 8   economic_status       60420 non-null  int64\n",
      " 9   cur_eco_activity      60420 non-null  int64\n",
      " 10  marital_status        60420 non-null  int64\n",
      " 11  occupation            60420 non-null  int64\n",
      "dtypes: int64(12)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "df['sex']=[1 if v == 'male' else 0 for v in df['sex']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes == 'object':\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "\n",
    "'''\n",
    "cts_features = ['household_size', 'edu_level', 'age', 'household_position']\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "df[cts_features] = ss.fit_transform(df[cts_features])\n",
    "'''\n",
    "\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a921a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    36655\n",
       "1    19656\n",
       "4     3566\n",
       "3      543\n",
       "Name: marital_status, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"marital_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e364942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "train, test_ = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_ = test_.reset_index(drop=True)\n",
    "train_oh, test_oh = copy.deepcopy(train), copy.deepcopy(test_)\n",
    "\n",
    "cts_features = ['household_size', 'edu_level', 'age', 'household_position']\n",
    "ss = StandardScaler()\n",
    "\n",
    "train_oh[cts_features] = ss.fit_transform(train_oh[cts_features])\n",
    "test_oh[cts_features] = ss.fit_transform(test_oh[cts_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4395d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>household_position</th>\n",
       "      <th>household_size</th>\n",
       "      <th>prev_residence_place</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>country_birth</th>\n",
       "      <th>edu_level</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>cur_eco_activity</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1121</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1110</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1121</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1132</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1122</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1121</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1122</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>133</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1110</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1210</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1110</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  household_position  household_size  prev_residence_place  \\\n",
       "0    0    7                1121             112                     1   \n",
       "1    1    4                1110             114                     1   \n",
       "2    0    7                1121             112                     1   \n",
       "3    1    8                1132             125                     1   \n",
       "4    1    8                1122             114                     1   \n",
       "5    1   10                1121             112                     1   \n",
       "6    0    7                1122             114                     1   \n",
       "7    0    6                1110             114                     1   \n",
       "8    0   11                1210             111                     1   \n",
       "9    1    8                1110             113                     1   \n",
       "\n",
       "   citizenship  country_birth  edu_level  economic_status  cur_eco_activity  \\\n",
       "0            1              1          3              111               122   \n",
       "1            1              1          2              111               131   \n",
       "2            1              1          4              111               134   \n",
       "3            1              1          1              111               134   \n",
       "4            1              1          5              120               138   \n",
       "5            1              1          3              111               122   \n",
       "6            1              1          3              111               133   \n",
       "7            1              1          5              111               131   \n",
       "8            1              1          1              111               139   \n",
       "9            1              1          1              111               122   \n",
       "\n",
       "   marital_status  occupation  \n",
       "0               2           0  \n",
       "1               1           0  \n",
       "2               2           0  \n",
       "3               4           0  \n",
       "4               2           1  \n",
       "5               2           1  \n",
       "6               2           0  \n",
       "7               1           1  \n",
       "8               4           0  \n",
       "9               1           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904c7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tailequy/fairness_dataset/blob/main/experiments/Fair-metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2c28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dh_oh = test_oh.loc[test_oh[\"sex\"] == 1]\n",
    "m_dh_oh = m_dh_oh.head(100)\n",
    "fm_dh_oh = test_oh.loc[test_oh[\"sex\"] == 0]\n",
    "fm_dh_oh = fm_dh_oh.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c535017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_oh.drop(columns=\"occupation\").values\n",
    "Y_train = train_oh['occupation'].values\n",
    "X_test = test_oh.drop(columns=\"occupation\").values\n",
    "Y_test = test_oh['occupation'].values\n",
    "X_m = m_dh_oh.drop(columns=\"occupation\").values\n",
    "Y_m = m_dh_oh['occupation'].values\n",
    "X_fm = fm_dh_oh.drop(columns=\"occupation\").values\n",
    "Y_fm = fm_dh_oh['occupation'].values\n",
    "\n",
    "#creating torch dataset and loader using original dataset. \n",
    "#to use resampled dataset, replace ex. xtrain with xtrain_over etc.\n",
    "train_data = torch.utils.data.TensorDataset(torch.tensor(X_train).float(), torch.tensor(Y_train).long())\n",
    "test_data = torch.utils.data.TensorDataset(torch.tensor(X_test).float(), torch.tensor(Y_test).long())\n",
    "m_data = torch.utils.data.TensorDataset(torch.tensor(X_m).float(), torch.tensor(Y_m).long())\n",
    "fm_data = torch.utils.data.TensorDataset(torch.tensor(X_fm).float(), torch.tensor(Y_fm).long())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data))\n",
    "m_loader = torch.utils.data.DataLoader(m_data, batch_size=1)\n",
    "fm_loader = torch.utils.data.DataLoader(fm_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e242062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.layers = 0\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(self.num_features,  150)        \n",
    "        self.lin2 = torch.nn.Linear(50, 50)        \n",
    "        self.lin3 = torch.nn.Linear(50, 50)\n",
    "        \n",
    "        self.lin4 = torch.nn.Linear(150, 150) \n",
    "        \n",
    "        self.lin5 = torch.nn.Linear(50, 50)        \n",
    "        self.lin6 = torch.nn.Linear(50, 50)\n",
    "        self.lin10 = torch.nn.Linear(150, self.num_classes)\n",
    "        \n",
    "        self.prelu = torch.nn.PReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        self.layers = 0\n",
    "        \n",
    "        x = F.relu(self.lin1(xin))\n",
    "        self.layers += 1\n",
    "        \n",
    "        #x = F.relu(self.lin2(x))\n",
    "        #self.layers += 1\n",
    "        for y in range(8):\n",
    "            x = F.relu(self.lin4(x)) \n",
    "            self.layers += 1\n",
    "           \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.lin10(x)) \n",
    "        self.layers += 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7df169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, target in train_loader:\n",
    "      \n",
    "        #inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target.long())\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac1d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_size = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      \n",
    "        for inputs, target in test_loader:\n",
    "            \n",
    "            #inputs, target = inputs.to(device), target.to(device)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            test_size += len(inputs)\n",
    "            test_loss += test_loss_fn(output, target.long()).item() \n",
    "            pred = output.max(1, keepdim=True)[1] \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= test_size\n",
    "    accuracy = correct / test_size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, test_size,\n",
    "        100. * accuracy))\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3540472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training beginning...\n",
      "Epoch  1 :\n",
      "\n",
      "Test set: Average loss: 0.4272, Accuracy: 9843/12084 (81%)\n",
      "\n",
      "Epoch  2 :\n",
      "\n",
      "Test set: Average loss: 0.4473, Accuracy: 9775/12084 (81%)\n",
      "\n",
      "Epoch  3 :\n",
      "\n",
      "Test set: Average loss: 0.4231, Accuracy: 9876/12084 (82%)\n",
      "\n",
      "Epoch  4 :\n",
      "\n",
      "Test set: Average loss: 0.4185, Accuracy: 9879/12084 (82%)\n",
      "\n",
      "Epoch  5 :\n",
      "\n",
      "Test set: Average loss: 0.4156, Accuracy: 9878/12084 (82%)\n",
      "\n",
      "Epoch  6 :\n",
      "\n",
      "Test set: Average loss: 0.4288, Accuracy: 9850/12084 (82%)\n",
      "\n",
      "Epoch  7 :\n",
      "\n",
      "Test set: Average loss: 0.4142, Accuracy: 9899/12084 (82%)\n",
      "\n",
      "Epoch  8 :\n",
      "\n",
      "Test set: Average loss: 0.4276, Accuracy: 9869/12084 (82%)\n",
      "\n",
      "Epoch  9 :\n",
      "\n",
      "Test set: Average loss: 0.4525, Accuracy: 9776/12084 (81%)\n",
      "\n",
      "Epoch  10 :\n",
      "\n",
      "Test set: Average loss: 0.4256, Accuracy: 9830/12084 (81%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BasicNet(11, 2)\n",
    "test_accuracy = []\n",
    "train_loss = []\n",
    "nbr_epochs = 10\n",
    "lr = 0.0005# \n",
    "weight_decay = 0\n",
    "\n",
    "# Surrogate loss used for training\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "test_loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr ,weight_decay=weight_decay)\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "print('Training beginning...')\n",
    "#start_time = time.time()\n",
    "\n",
    "for epoch in range(1, nbr_epochs+1):\n",
    "    print('Epoch ', epoch, ':')\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    loss, acc = test(model, test_loader)\n",
    "    \n",
    "    # save results every epoch\n",
    "    test_accuracy.append(acc)\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "#end_time = time.time()\n",
    "#print('Training on ' + str(nbr_epochs) + ' epochs done in ', str(end_time-start_time),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cca14a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 9830/12084 (81%)\n",
      "\n",
      "5749 tensor([6253]) tensor([6253])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, target in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        pred = outputs.max(1, keepdim=True)[1] \n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(inputs)\n",
    "        print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(inputs), 100. * accuracy))\n",
    "\n",
    "Y_prob = F.softmax(outputs, dim=1)[:, 1]\n",
    "Y_pred = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "print(sum(Y_test), sum(Y_pred), sum(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f221b5",
   "metadata": {},
   "source": [
    "<h1>Demographic Parity</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de150a4",
   "metadata": {},
   "source": [
    "<h2>Distribution of scores by sex</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae1acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity difference: 0.415\n",
      "Demographic parity ratio: 0.429\n"
     ]
    }
   ],
   "source": [
    "dpd = demographic_parity_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "dpr = demographic_parity_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "print(f\"Demographic parity difference: {dpd:.3f}\")\n",
    "print(f\"Demographic parity ratio: {dpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60d29f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional demographic parity difference: 0.429\n",
      "Conditional demographic parity ratio: 0.422\n"
     ]
    }
   ],
   "source": [
    "test_edu_level_enum = test_oh.marital_status.map(bin_marital_status_level)\n",
    "\n",
    "cdpd = conditional_demographic_parity_difference(\n",
    "    Y_test, Y_pred, test_oh.sex, test_edu_level_enum,\n",
    ")\n",
    "cdpr = conditional_demographic_parity_ratio(\n",
    "    Y_test, Y_pred, test_oh.sex, test_edu_level_enum,\n",
    ")\n",
    "\n",
    "print(f\"Conditional demographic parity difference: {cdpd:.3f}\")\n",
    "print(f\"Conditional demographic parity ratio: {cdpr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540eb7be",
   "metadata": {},
   "source": [
    "<h1>Equalised Odds</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83403a17",
   "metadata": {},
   "source": [
    "<h2>Distribution of scores by sex</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb4a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalised odds difference: 0.321\n",
      "Equalised odds ratio: 0.242\n"
     ]
    }
   ],
   "source": [
    "eod = equalized_odds_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "eor = equalized_odds_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "print(f\"Equalised odds difference: {eod:.3f}\")\n",
    "print(f\"Equalised odds ratio: {eor:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025501d",
   "metadata": {},
   "source": [
    "<h1>Shapley based Neuron Pruning for Fairness</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "907f2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3166945e-01 2.1132304e-01 1.0634838e-01 ... 2.6115302e+02 3.7410034e+02\n",
      " 0.0000000e+00]\n",
      "[0.0000000e+00 2.1125238e-01 8.4636174e-02 ... 2.7463034e+02 3.6162741e+02\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "m_shapley_values = ns.calculate_shapley_values_fa(model, m_loader, 200)\n",
    "print(m_shapley_values)\n",
    "fm_shapley_values = ns.calculate_shapley_values_fa(model, fm_loader, 200)\n",
    "print(fm_shapley_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66e84c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.5969777,   4.6008453,   4.65987  ,   4.631687 ,   4.6606836,\n",
       "         4.6752243,   4.713539 ,   4.759605 ,   4.794897 ,   4.815467 ,\n",
       "         6.9915314,   5.67606  ,   5.8513794,   5.6466827,   5.784607 ,\n",
       "         7.102893 ,   6.3799515,   5.892618 ,   5.058113 ,   5.4610977,\n",
       "         7.452131 ,   5.9004517,   5.9830475,   6.3224106,   7.1398087,\n",
       "         6.4203486,   5.5566444,   6.425995 ,   6.811697 ,   5.6460266,\n",
       "         5.1214027,   4.956169 ,   5.622612 ,   5.456482 ,   7.0394897,\n",
       "         5.4711304,   4.903763 ,   6.121045 ,   5.594913 ,   6.1698313,\n",
       "         5.1408467,   5.0873475,   5.827774 ,   6.4503784,   4.8939457,\n",
       "         5.054886 ,   5.4267373,   6.6896896,   6.2931075,   7.135277 ,\n",
       "         5.1973953,   6.047806 ,   5.5499725,   6.9853897,   7.145598 ,\n",
       "         6.176979 ,   4.9336243,   7.464119 ,   4.8598366,   5.058899 ,\n",
       "         7.74572  ,   8.84137  ,  14.776009 ,   8.050171 ,  13.737697 ,\n",
       "       333.34973  , 367.6952   ,  18.073124 ,  13.723068 ,  23.944473 ,\n",
       "        10.606085 ,   9.33099  ,   9.485807 ,   8.696782 ,   8.810097 ,\n",
       "        10.430763 ,  13.207672 ,   9.594772 ,  15.31866  ,  15.8198185,\n",
       "         9.418549 ,  14.94059  ,  15.557911 ,  20.618896 ,   7.8220215,\n",
       "        14.43536  ,   9.558426 ,   8.416252 ,  12.472931 ,   8.820209 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_shap_values = m_shapley_values - fm_shapley_values\n",
    "max_diff_shap_values_ind = np.argpartition(diff_shap_values, -90)[-90:]\n",
    "diff_shap_values[max_diff_shap_values_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3373eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arr, model_slist = sim.get_net_arr(model)\n",
    "model_arr[max_diff_shap_values_ind] = 0\n",
    "updated_model = sim.get_arr_net(model, model_arr, model_slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36e1159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 7695/12084 (64%)\n",
      "\n",
      "5749 tensor([1562]) tensor([1562])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, target in test_loader:\n",
    "        outputs = updated_model(inputs)\n",
    "        pred = outputs.max(1, keepdim=True)[1] \n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(inputs)\n",
    "        print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(inputs), 100. * accuracy))\n",
    "        \n",
    "\n",
    "Y_prob = F.softmax(outputs, dim=1)[:, 1]\n",
    "Y_pred = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "print(sum(Y_test), sum(Y_pred), sum(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39c508d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity difference: 0.067\n",
      "Demographic parity ratio: 0.587\n"
     ]
    }
   ],
   "source": [
    "dpd = demographic_parity_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "dpr = demographic_parity_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "print(f\"Demographic parity difference: {dpd:.3f}\")\n",
    "print(f\"Demographic parity ratio: {dpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5212784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional demographic parity difference: 0.054\n",
      "Conditional demographic parity ratio: 0.714\n"
     ]
    }
   ],
   "source": [
    "test_marital_status_enum = test_oh.marital_status.map(bin_marital_status_level)\n",
    "\n",
    "cdpd = conditional_demographic_parity_difference(\n",
    "    Y_test, Y_pred, test_oh.sex, test_marital_status_enum,\n",
    ")\n",
    "cdpr = conditional_demographic_parity_ratio(\n",
    "    Y_test, Y_pred, test_oh.sex, test_marital_status_enum,\n",
    ")\n",
    "\n",
    "print(f\"Conditional demographic parity difference: {cdpd:.3f}\")\n",
    "print(f\"Conditional demographic parity ratio: {cdpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "946bca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalised odds difference: 0.002\n",
      "Equalised odds ratio: 0.969\n"
     ]
    }
   ],
   "source": [
    "eod = equalized_odds_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "eor = equalized_odds_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "print(f\"Equalised odds difference: {eod:.3f}\")\n",
    "print(f\"Equalised odds ratio: {eor:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319c710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169d90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:menv]",
   "language": "python",
   "name": "conda-env-menv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
