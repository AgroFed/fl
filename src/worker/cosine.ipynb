{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import fl, nn, agg, data, poison, log, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"debug\")\n",
    "#log.init(\"info\", \"federated.log\")\n",
    "#log.init(\"debug\", \"flkafka.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedArgs():\n",
    "    def __init__(self):\n",
    "        self.num_clients = 50\n",
    "        self.epochs = 10\n",
    "        self.local_rounds = 1\n",
    "        self.client_batch_size = 32\n",
    "        self.test_batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.cuda = True\n",
    "        self.seed = 1\n",
    "        self.tb = SummaryWriter('../../out/runs/federated/FLTrust', comment=\"Mnist Centralized Federated training\")\n",
    "\n",
    "fedargs = FedArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Global and Client models\n",
    "global_model = nn.ModelMNIST()\n",
    "client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "# Function for training\n",
    "def train_model(_model, train_loader, fedargs, device):\n",
    "    model, loss = fl.client_update(_model,\n",
    "                                train_loader,\n",
    "                                fedargs.learning_rate,\n",
    "                                fedargs.weight_decay,\n",
    "                                fedargs.local_rounds,\n",
    "                                device)\n",
    "    model_update = agg.sub_model(_model, model)\n",
    "    return model_update, model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Data to clients\n",
    "train_data, test_data = data.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For FLTrust\n",
    "#############Skip this section for running other averaging\n",
    "FLTrust = True\n",
    "root_ratio = 0.01\n",
    "train_data, root_data = torch.utils.data.random_split(train_data, [int(len(train_data) * (1-root_ratio)), \n",
    "                                                              int(len(train_data) * root_ratio)])\n",
    "root_loader = torch.utils.data.DataLoader(root_data, batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "#global_model, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "#client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison a client\n",
    "################Skip this section for running without poison\n",
    "for client in range(10):\n",
    "    clients_data[clients[client]] = poison.label_flip(clients_data[clients[client]], 4, 9, poison_percent = -1)\n",
    "    \n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 6, 2, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 3, 8, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 1, 5, poison_percent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "clients_info = {\n",
    "        client: {\"train_loader\": client_train_loaders[client]}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = copy.deepcopy(global_model)\n",
    "\n",
    "C1 = copy.deepcopy(global_model)\n",
    "C2 = copy.deepcopy(global_model)\n",
    "\n",
    "C3 = copy.deepcopy(global_model)\n",
    "C4 = copy.deepcopy(global_model)\n",
    "C5 = copy.deepcopy(global_model)\n",
    "\n",
    "#for i in range(3):\n",
    "_B1, B1, _ = train_model(B1, root_loader, fedargs, device)\n",
    "\n",
    "_C3, C3, _ = train_model(C3, clients_info[list(clients_info.keys())[21]]['train_loader'], fedargs, device)\n",
    "_C4, C4, _ = train_model(C4, clients_info[list(clients_info.keys())[22]]['train_loader'], fedargs, device)\n",
    "_C5, C5, _ = train_model(C5, clients_info[list(clients_info.keys())[23]]['train_loader'], fedargs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/harsh_1921cs01/hub/F3IA/fl/libs/sim.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  _param_list = nd.array(param_list).squeeze()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10440999\n",
      "[array(0.24124, dtype=float32), array(0.0403336, dtype=float32), array(0.10411313, dtype=float32), array(0.19308683, dtype=float32)]\n",
      "0.14469338953495026\n",
      "###################################\n",
      "0.087574705\n",
      "[array(0.07573985, dtype=float32), array(0.03305238, dtype=float32), array(0.09019455, dtype=float32), array(0.20181827, dtype=float32)]\n",
      "0.10020126402378082\n",
      "###################################\n",
      "0.52985364\n",
      "[array(0.56401443, dtype=float32), array(0.5321269, dtype=float32), array(0.5289359, dtype=float32), array(0.5586356, dtype=float32)]\n",
      "0.5459282100200653\n",
      "###################################\n",
      "0.56827354\n",
      "[array(0.5533229, dtype=float32), array(0.51556665, dtype=float32), array(0.5624943, dtype=float32), array(0.5380424, dtype=float32)]\n",
      "0.5423565655946732\n",
      "###################################\n",
      "0.5390002\n",
      "[array(0.5482059, dtype=float32), array(0.5267581, dtype=float32), array(0.5415623, dtype=float32), array(0.51956785, dtype=float32)]\n",
      "0.5340235382318497\n"
     ]
    }
   ],
   "source": [
    "#for j in range(20):\n",
    "_C1, C1, _ = train_model(C1, clients_info[list(clients_info.keys())[1]]['train_loader'], fedargs, device)\n",
    "_C2, C2, _ = train_model(C2, clients_info[list(clients_info.keys())[2]]['train_loader'], fedargs, device)\n",
    "\n",
    "print(sim.grad_cosine_similarity(_B1, _C1))\n",
    "print(sim._grad_cosine_similarity(_B1, _C1))\n",
    "\n",
    "print(\"###################################\")\n",
    "\n",
    "print(sim.grad_cosine_similarity(_B1, _C2))\n",
    "print(sim._grad_cosine_similarity(_B1, _C2))\n",
    "\n",
    "print(\"###################################\")\n",
    "\n",
    "print(sim.grad_cosine_similarity(_B1, _C3))\n",
    "print(sim._grad_cosine_similarity(_B1, _C3))\n",
    "\n",
    "print(\"###################################\")\n",
    "\n",
    "print(sim.grad_cosine_similarity(_B1, _C4))\n",
    "print(sim._grad_cosine_similarity(_B1, _C4))\n",
    "\n",
    "print(\"###################################\")\n",
    "\n",
    "print(sim.grad_cosine_similarity(_B1, _C5))\n",
    "print(sim._grad_cosine_similarity(_B1, _C5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 09:48:56,834 - /home2/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : FLTrust Score [0.104, 0.088, 0.53, 0.568, 0.539] [MainProcess : MainThread (INFO)]\n",
      "2021-08-24 09:48:57,422 - /home2/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : FLTrust Score [1.001, 1.001, 0.53, 0.568, 0.539] [MainProcess : MainThread (INFO)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 1.5952611003875732, 'correct': 6643, 'accuracy': 66.43}\n",
      "{'test_loss': 1.6413420360565185, 'correct': 5800, 'accuracy': 57.99999999999999}\n"
     ]
    }
   ],
   "source": [
    "def sub_model(model1, model2):\n",
    "    params1 = model1.state_dict().copy()\n",
    "    params2 = model2.state_dict().copy()\n",
    "    \n",
    "    params1['conv1.weight'] = params2['conv1.weight']\n",
    "    #params1['fc1.weight'] = params2['fc1.weight']\n",
    "    \n",
    "    model = copy.deepcopy(model1)\n",
    "    model.load_state_dict(params1, strict=False)\n",
    "    return model\n",
    "\n",
    "_C1_ = copy.deepcopy(_C1)\n",
    "_C1_ = sub_model(_B1, _C1_)\n",
    "\n",
    "_C2_ = copy.deepcopy(_C2)\n",
    "_C2_ = sub_model(_B1, _C2_)\n",
    "\n",
    "#print(sim.grad_cosine_similarity(_B1, _C1_))\n",
    "#print(sim._grad_cosine_similarity(_B1, _C1_))\n",
    "\n",
    "avgargs = {\"base_update\": _B1}\n",
    "t1 = fl.federated_avg({'a': _C1, 'b': _C2, 'c': _C3, 'd': _C4, 'e': _C5}, B1, agg.Rule.FLTrust, **avgargs)\n",
    "t2 = fl.federated_avg({'a': _C1_, 'b': _C2_, 'c': _C3, 'd': _C4, 'e': _C5}, B1, agg.Rule.FLTrust, **avgargs)\n",
    "\n",
    "print(fl.eval(t1, test_loader, device))\n",
    "print(fl.eval(t2, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 1, 3, 3), (32,), (64, 32, 3, 3), (64,), (128, 9216), (128,), (10, 128), (10,)]\n",
      "(1199882,)\n",
      "\n",
      "[0.10440999]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[0.5390002]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd as mnd\n",
    "\n",
    "fb1, bslist = sim.get_net_arr(_B1)\n",
    "fc1, cslist = sim.get_net_arr(_C1)\n",
    "fc5, cslist = sim.get_net_arr(_C5)\n",
    "\n",
    "print(bslist)\n",
    "\n",
    "print(fb1.shape)\n",
    "\n",
    "cs1 = mnd.dot(mnd.array(fb1), mnd.array(fc1)) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(fc1)) + 1e-9)\n",
    "cs5 = mnd.dot(mnd.array(fb1), mnd.array(fc5)) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(fc5)) + 1e-9)\n",
    "\n",
    "print(cs1, cs5)\n",
    "#_T1 = sim.get_arr_net(_C1, fc1, slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.denoising_model().to(device)\n",
    "criterion=torch.nn.MSELoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.5,weight_decay=1e-5)\n",
    "\n",
    "output = fc1\n",
    "model.train()\n",
    "for epcoh in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(torch.from_numpy(fc1))\n",
    "    cs1 = mnd.dot(mnd.array(fb1), mnd.array(output.detach().numpy())) / (mnd.norm(mnd.array(fb1)) + 1e-9) / (mnd.norm(mnd.array(output.detach().numpy())) + 1e-9)\n",
    "    _loss = criterion(output, torch.from_numpy(fb1))\n",
    "    _loss = _loss + cs1.asnumpy()[0]\n",
    "    print(_loss)\n",
    "    _loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
