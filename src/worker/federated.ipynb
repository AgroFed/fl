{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import fl, nn, agg, data, poison, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "#log.init(\"info\", \"federated.log\")\n",
    "#log.init(\"debug\", \"flkafka.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedArgs():\n",
    "    def __init__(self):\n",
    "        self.num_clients = 50\n",
    "        self.epochs = 10\n",
    "        self.local_rounds = 1\n",
    "        self.client_batch_size = 32\n",
    "        self.test_batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.cuda = False\n",
    "        self.seed = 1\n",
    "        self.tb = SummaryWriter('../../out/runs/federated/FLTrust', comment=\"Mnist Centralized Federated training\")\n",
    "\n",
    "fedargs = FedArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Global and Client models\n",
    "global_model = nn.ModelMNIST()\n",
    "client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "# Function for training\n",
    "def train_model(_model, train_loader, fedargs, device):\n",
    "    model, loss = fl.client_update(_model,\n",
    "                                train_loader,\n",
    "                                fedargs.learning_rate,\n",
    "                                fedargs.weight_decay,\n",
    "                                fedargs.local_rounds,\n",
    "                                device)\n",
    "    model_update = agg.sub_model(_model, model)\n",
    "    return model_update, model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Data to clients\n",
    "train_data, test_data = data.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For securing if the next cell execution is skipped\n",
    "FLTrust = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>FLTrust: Skip section below for any other averaging than FLTrust.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For FLTrust\n",
    "#############Skip this section for running other averaging\n",
    "FLTrust = True\n",
    "root_ratio = 0.01\n",
    "train_data, root_data = torch.utils.data.random_split(train_data, [int(len(train_data) * (1-root_ratio)), \n",
    "                                                              int(len(train_data) * root_ratio)])\n",
    "root_loader = torch.utils.data.DataLoader(root_data, batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "#global_model, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "#client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Poison: Skip section below to run normal, modify if required.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison a client\n",
    "################Skip this section for running without poison\n",
    "for client in range(10):\n",
    "    clients_data[clients[client]] = poison.label_flip(clients_data[clients[client]], 4, 9, poison_percent = -1)\n",
    "    \n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 6, 2, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 3, 8, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 1, 5, poison_percent = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "clients_info = {\n",
    "        client: {\"train_loader\": client_train_loaders[client]}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = train_model(model, train_loader, fedargs, device)\n",
    "\n",
    "    #Plot and Log\n",
    "    for local_epoch, loss in enumerate(list(loss.values())):\n",
    "        fedargs.tb.add_scalars(\"Training Loss/\" + client, {str(epoch): loss}, str(local_epoch + 1))\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2021-08-18 16:07:39,019 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 1 of 10 [MainProcess : MainThread (INFO)]\n",
      " 10%|█         | 1/10 [00:33<05:03, 33.70s/it]2021-08-18 16:08:12,720 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 2 of 10 [MainProcess : MainThread (INFO)]\n",
      "/home/harsh_1921cs01/hub/F3IA/fl/libs/sim.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  _param_list = nd.array(param_list).squeeze()\n",
      "2021-08-18 16:08:19,399 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : TS_SCORE [0.141, 0.145, 0.149, 0.142, 0.14, 0.132, 0.141, 0.139, 0.131, 0.14, 0.522, 0.523, 0.506, 0.486, 0.552, 0.516, 0.49, 0.546, 0.539, 0.551, 0.506, 0.51, 0.512, 0.473, 0.538, 0.528, 0.492, 0.516, 0.518, 0.537, 0.535, 0.536, 0.519, 0.531, 0.488, 0.48, 0.529, 0.521, 0.543, 0.483, 0.526, 0.514, 0.546, 0.52, 0.53, 0.513, 0.537, 0.53, 0.516, 0.542] [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:08:25,953 - <ipython-input-102-5f39cab2337c>::<module>(l:31) : Gloabl Test Outut after Epoch 2 of 10 {\n",
      "    \"accuracy\": 61.69,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 831,\n",
      "        \"attack_success_rate\": 84.62321792260693,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 87.27087576374745,\n",
      "        \"misclassifications\": 857\n",
      "    },\n",
      "    \"correct\": 6169,\n",
      "    \"test_loss\": 1.878939322280884\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 20%|██        | 2/10 [01:20<05:30, 41.32s/it]2021-08-18 16:08:59,367 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 3 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:09:06,148 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : TS_SCORE [0.129, 0.133, 0.124, 0.124, 0.129, 0.124, 0.122, 0.118, 0.121, 0.125, 0.686, 0.687, 0.707, 0.707, 0.716, 0.698, 0.669, 0.702, 0.689, 0.678, 0.686, 0.711, 0.698, 0.702, 0.713, 0.719, 0.694, 0.681, 0.696, 0.692, 0.717, 0.704, 0.68, 0.713, 0.711, 0.705, 0.696, 0.697, 0.704, 0.708, 0.708, 0.712, 0.706, 0.673, 0.718, 0.704, 0.719, 0.671, 0.7, 0.685] [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:09:12,372 - <ipython-input-102-5f39cab2337c>::<module>(l:31) : Gloabl Test Outut after Epoch 3 of 10 {\n",
      "    \"accuracy\": 76.34,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 580,\n",
      "        \"attack_success_rate\": 59.063136456211815,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 63.34012219959266,\n",
      "        \"misclassifications\": 622\n",
      "    },\n",
      "    \"correct\": 7634,\n",
      "    \"test_loss\": 1.2199103433609009\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 30%|███       | 3/10 [02:06<05:03, 43.36s/it]2021-08-18 16:09:45,146 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 4 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:09:51,461 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : TS_SCORE [0.063, 0.07, 0.067, 0.065, 0.069, 0.062, 0.06, 0.063, 0.068, 0.062, 0.671, 0.651, 0.653, 0.648, 0.674, 0.662, 0.659, 0.661, 0.662, 0.659, 0.676, 0.669, 0.667, 0.649, 0.648, 0.647, 0.647, 0.652, 0.664, 0.648, 0.647, 0.666, 0.655, 0.658, 0.632, 0.642, 0.662, 0.663, 0.676, 0.638, 0.646, 0.666, 0.636, 0.643, 0.657, 0.66, 0.639, 0.665, 0.674, 0.674] [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:09:58,262 - <ipython-input-102-5f39cab2337c>::<module>(l:31) : Gloabl Test Outut after Epoch 4 of 10 {\n",
      "    \"accuracy\": 83.37,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 306,\n",
      "        \"attack_success_rate\": 31.160896130346234,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 35.336048879837065,\n",
      "        \"misclassifications\": 347\n",
      "    },\n",
      "    \"correct\": 8337,\n",
      "    \"test_loss\": 0.7817515171051025\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 40%|████      | 4/10 [02:51<04:25, 44.24s/it]2021-08-18 16:10:30,757 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 5 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:10:37,046 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : TS_SCORE [0.018, 0.018, 0.017, 0.018, 0.02, 0.013, 0.015, 0.015, 0.011, 0.015, 0.538, 0.526, 0.54, 0.553, 0.553, 0.562, 0.55, 0.522, 0.542, 0.554, 0.551, 0.547, 0.532, 0.554, 0.557, 0.545, 0.533, 0.538, 0.548, 0.548, 0.547, 0.548, 0.559, 0.55, 0.556, 0.537, 0.524, 0.535, 0.545, 0.541, 0.526, 0.533, 0.535, 0.548, 0.551, 0.538, 0.541, 0.539, 0.539, 0.542] [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:10:43,197 - <ipython-input-102-5f39cab2337c>::<module>(l:31) : Gloabl Test Outut after Epoch 5 of 10 {\n",
      "    \"accuracy\": 87.14,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 140,\n",
      "        \"attack_success_rate\": 14.25661914460285,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 18.839103869653766,\n",
      "        \"misclassifications\": 185\n",
      "    },\n",
      "    \"correct\": 8714,\n",
      "    \"test_loss\": 0.5610457911491394\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 50%|█████     | 5/10 [03:36<03:42, 44.48s/it]2021-08-18 16:11:15,646 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 6 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:11:21,917 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : TS_SCORE [0.028, 0.034, 0.031, 0.03, 0.028, 0.017, 0.027, 0.029, 0.024, 0.03, 0.382, 0.377, 0.395, 0.396, 0.389, 0.416, 0.391, 0.4, 0.383, 0.407, 0.4, 0.395, 0.399, 0.392, 0.388, 0.391, 0.398, 0.367, 0.37, 0.392, 0.4, 0.391, 0.393, 0.364, 0.378, 0.395, 0.377, 0.366, 0.393, 0.376, 0.382, 0.373, 0.377, 0.39, 0.418, 0.368, 0.389, 0.394, 0.408, 0.384] [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:11:28,597 - <ipython-input-102-5f39cab2337c>::<module>(l:31) : Gloabl Test Outut after Epoch 6 of 10 {\n",
      "    \"accuracy\": 88.66000000000001,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 121,\n",
      "        \"attack_success_rate\": 12.321792260692463,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 16.08961303462322,\n",
      "        \"misclassifications\": 158\n",
      "    },\n",
      "    \"correct\": 8866,\n",
      "    \"test_loss\": 0.45346838040351867\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 60%|██████    | 6/10 [04:22<02:59, 44.90s/it]2021-08-18 16:12:01,361 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 7 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:12:07,719 - /home/harsh_1921cs01/hub/F3IA/fl/libs/agg.py::FLTrust(l:90) : TS_SCORE [0.005, 0.005, 0.0, 0.002, 0.006, 0, 0, 0, 0, 0, 0.271, 0.279, 0.299, 0.273, 0.273, 0.309, 0.277, 0.277, 0.265, 0.277, 0.279, 0.287, 0.276, 0.283, 0.274, 0.3, 0.272, 0.251, 0.256, 0.258, 0.285, 0.298, 0.279, 0.276, 0.257, 0.268, 0.253, 0.263, 0.282, 0.267, 0.253, 0.243, 0.274, 0.285, 0.282, 0.272, 0.286, 0.295, 0.268, 0.238] [MainProcess : MainThread (INFO)]\n",
      "2021-08-18 16:12:14,364 - <ipython-input-102-5f39cab2337c>::<module>(l:31) : Gloabl Test Outut after Epoch 7 of 10 {\n",
      "    \"accuracy\": 90.16,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 65,\n",
      "        \"attack_success_rate\": 6.619144602851323,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 10.386965376782078,\n",
      "        \"misclassifications\": 102\n",
      "    },\n",
      "    \"correct\": 9016,\n",
      "    \"test_loss\": 0.38973498854637145\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 70%|███████   | 7/10 [05:07<02:15, 45.14s/it]2021-08-18 16:12:46,996 - <ipython-input-102-5f39cab2337c>::<module>(l:8) : Federated Training Epoch 8 of 10 [MainProcess : MainThread (INFO)]\n",
      " 70%|███████   | 7/10 [05:10<02:13, 44.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-5f39cab2337c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_model_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLTrust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mavgargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeldebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Epoch {} of {} : Server Update\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfedargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hub/F3IA/fl/libs/fl.py\u001b[0m in \u001b[0;36mfederated_avg\u001b[0;34m(models, base_model, rule, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFedAvg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLTrust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLTrust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hub/F3IA/fl/libs/agg.py\u001b[0m in \u001b[0;36mFLTrust\u001b[0;34m(base_model, models, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Model Norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mndiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_norm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hub/F3IA/fl/libs/sim.py\u001b[0m in \u001b[0;36mgrad_norm\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mx_net_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hub/F3IA/fl/libs/sim.py\u001b[0m in \u001b[0;36mget_mx_net_arr\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for _epoch in tqdm(range(fedargs.epochs)):\n",
    "\n",
    "    epoch = _epoch + 1\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Gloabal Model Update\n",
    "    if epoch > 1:\n",
    "        # For Tmean, not impacts others as of now\n",
    "        avgargs = {\"beta\": 10}\n",
    "        \n",
    "        # For FLTrust, if FLTrust section is skipped, this piece of code will be ignored automatically\n",
    "        if FLTrust:\n",
    "            global_model_update, _, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "            avgargs[\"base_update\"] = global_model_update\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_model_updates, global_model, agg.Rule.FLTrust, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {} of {} : Server Update\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Test\n",
    "        global_test_output = fl.eval(global_model, test_loader, device, 4, 9)\n",
    "        fedargs.tb.add_scalars(\"Test Evaluation\", {\n",
    "            'Gloabl Accuracy': global_test_output[\"accuracy\"],\n",
    "            'Attack Success Rate': global_test_output[\"attack\"][\"attack_success_rate\"],\n",
    "            'Misclassification Rate': global_test_output[\"attack\"][\"misclassification_rate\"],\n",
    "        }, epoch)\n",
    "        log.jsoninfo(global_test_output, \"Gloabl Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "    \n",
    "        # Update client models\n",
    "        client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "    # Clients\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [process(client, epoch, client_models[client],\n",
    "                     clients_info[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    updates = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    client_model_updates = {client: update for client, update in zip(clients, updates)}\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
