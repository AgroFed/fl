{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70a77f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import socket\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import fl, nn, agg, data, poison, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c9749cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "#log.init(\"info\", \"federated.log\")\n",
    "#log.init(\"debug\", \"flkafka.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea0623fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedArgs():\n",
    "    def __init__(self):\n",
    "        self.num_clients = 50\n",
    "        self.epochs = 10\n",
    "        self.local_rounds = 1\n",
    "        self.client_batch_size = 32\n",
    "        self.test_batch_size = 128\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-5\n",
    "        self.cuda = False\n",
    "        self.seed = 1\n",
    "        self.tb = SummaryWriter('../../out/runs/federated/FLTrust', comment=\"Mnist Centralized Federated training\")\n",
    "\n",
    "fedargs = FedArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a3022ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e8de969",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddb39627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Global and Client models\n",
    "global_model = nn.ModelMNIST()\n",
    "client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "# Function for training\n",
    "def train_model(model, train_loader, fedargs, device):\n",
    "    model, loss = fl.client_update(model,\n",
    "                                train_loader,\n",
    "                                fedargs.learning_rate,\n",
    "                                fedargs.weight_decay,\n",
    "                                fedargs.local_rounds,\n",
    "                                device)\n",
    "    return model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7283a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Data to clients\n",
    "train_data, test_data = data.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca8437f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For securing if the next cell execution is skipped\n",
    "FLTrust = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652b243",
   "metadata": {},
   "source": [
    "<h1>FLTrust: Skip section below for any other averaging than FLTrust.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7aeefe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For FLTrust\n",
    "#############Skip this section for running other averaging\n",
    "FLTrust = True\n",
    "root_ratio = 0.01\n",
    "train_data, root_data = torch.utils.data.random_split(train_data, [int(len(train_data) * (1-root_ratio)), \n",
    "                                                              int(len(train_data) * root_ratio)])\n",
    "root_loader = torch.utils.data.DataLoader(root_data, batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "#global_model, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "#client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "#############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7c918",
   "metadata": {},
   "source": [
    "<h2>Resume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb85449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ccaed",
   "metadata": {},
   "source": [
    "<h1>Poison: Skip section below to run normal, modify if required.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3a79039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison a client\n",
    "################Skip this section for running without poison\n",
    "for client in range(10):\n",
    "    clients_data[clients[client]] = poison.label_flip(clients_data[clients[client]], 4, 9, poison_percent = -1)\n",
    "    \n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 6, 2, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 3, 8, poison_percent = 1)\n",
    "#clients_data[clients[0]] = poison.label_flip(clients_data[clients[0]], 1, 5, poison_percent = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d1cc4",
   "metadata": {},
   "source": [
    "<h2>Resume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fea97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "clients_info = {\n",
    "        client: {\"train_loader\": client_train_loaders[client]}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdb33528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model, loss = train_model(model, train_loader, fedargs, device)\n",
    "\n",
    "    #Plot and Log\n",
    "    for local_epoch, loss in enumerate(list(loss.values())):\n",
    "        fedargs.tb.add_scalars(\"Training Loss/\" + client, {str(epoch): loss}, str(local_epoch + 1))\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2021-08-17 11:03:15,422 - <ipython-input-75-c672cc171386>::<module>(l:8) : Federated Training Epoch 1 of 10 [MainProcess : MainThread (INFO)]\n",
      " 10%|█         | 1/10 [00:33<05:03, 33.72s/it]2021-08-17 11:03:49,147 - <ipython-input-75-c672cc171386>::<module>(l:8) : Federated Training Epoch 2 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-17 11:03:55,519 - <ipython-input-75-c672cc171386>::<module>(l:30) : Gloabl Test Outut after Epoch 2 of 10 {\n",
      "    \"accuracy\": 74.26,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 268,\n",
      "        \"attack_success_rate\": 27.29124236252546,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 34.72505091649695,\n",
      "        \"misclassifications\": 341\n",
      "    },\n",
      "    \"correct\": 7426,\n",
      "    \"test_loss\": 1.4976529468536377\n",
      "} [MainProcess : MainThread (INFO)]\n",
      " 20%|██        | 2/10 [01:16<05:10, 38.86s/it]2021-08-17 11:04:31,609 - <ipython-input-75-c672cc171386>::<module>(l:8) : Federated Training Epoch 3 of 10 [MainProcess : MainThread (INFO)]\n",
      "2021-08-17 11:04:37,623 - <ipython-input-75-c672cc171386>::<module>(l:30) : Gloabl Test Outut after Epoch 3 of 10 {\n",
      "    \"accuracy\": 84.96000000000001,\n",
      "    \"attack\": {\n",
      "        \"attack_success_count\": 122,\n",
      "        \"attack_success_rate\": 12.423625254582484,\n",
      "        \"instances\": 982,\n",
      "        \"misclassification_rate\": 18.329938900203665,\n",
      "        \"misclassifications\": 180\n",
      "    },\n",
      "    \"correct\": 8496,\n",
      "    \"test_loss\": 0.6765399671554565\n",
      "} [MainProcess : MainThread (INFO)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for _epoch in tqdm(range(fedargs.epochs)):\n",
    "\n",
    "    epoch = _epoch + 1\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Gloabal Model Update\n",
    "    if epoch > 1:\n",
    "        # For Tmean, not impacts others as of now\n",
    "        avgargs = {\"beta\": 10}\n",
    "        \n",
    "        # For FLTrust, if FLTrust section is skipped, this piece of code will be ignored automatically\n",
    "        if FLTrust:\n",
    "            global_model, _ = train_model(global_model, root_loader, fedargs, device)\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_models, global_model, agg.Rule.FedAvg, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {} of {} : Server Update\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Test\n",
    "        global_test_output = fl.eval(global_model, test_loader, device, 4, 9)\n",
    "        fedargs.tb.add_scalars(\"Test Evaluation\", {\n",
    "            'Gloabl Accuracy': global_test_output[\"accuracy\"],\n",
    "            'Attack Success Rate': global_test_output[\"attack\"][\"attack_success_rate\"],\n",
    "            'Misclassification Rate': global_test_output[\"attack\"][\"misclassification_rate\"],\n",
    "        }, epoch)\n",
    "        log.jsoninfo(global_test_output, \"Gloabl Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "    \n",
    "        # Update client models\n",
    "        client_models = {client: copy.deepcopy(global_model) for client in clients}\n",
    "\n",
    "    # Clients\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [process(client, epoch, client_models[client],\n",
    "                     clients_info[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    updates = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    client_models = {client: update for client, update in zip(clients, updates)}\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syft]",
   "language": "python",
   "name": "conda-env-syft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
